{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to install this for clinical coding\n",
    "# !pip install scispacy\n",
    "# !pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yu61Jp1xrnKk"
   },
   "outputs": [],
   "source": [
    "# import  packages you need\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "from typing import Callable, Dict, List, Optional, Tuple\n",
    "import csv\n",
    "import json, time\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from itertools import combinations, islice\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyhealth\n",
    "from pyhealth.medcode import InnerMap\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import scispacy #from above\n",
    "import spacy #from above\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 0 Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Franlk\\AppData\\Local\\Temp\\ipykernel_19608\\2097346371.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diags10.loc[:, 'contains_C25'] = (diags10.loc[:,'icd_code'].str.contains('C25')).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97301, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000117</td>\n",
       "      <td>22927623</td>\n",
       "      <td>0</td>\n",
       "      <td>EXAMINATION:   CHEST (PA AND LAT)\\n\\nINDICATIO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000117</td>\n",
       "      <td>27988844</td>\n",
       "      <td>0</td>\n",
       "      <td>EXAMINATION:  Left hip radiographs, two views,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000980</td>\n",
       "      <td>20897796</td>\n",
       "      <td>0</td>\n",
       "      <td>EXAMINATION:  BILAT LOWER EXT VEINS\\n\\nINDICAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25911675</td>\n",
       "      <td>0</td>\n",
       "      <td>EXAMINATION:  Chest radiograph.\\n\\nINDICATION:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000980</td>\n",
       "      <td>29659838</td>\n",
       "      <td>0</td>\n",
       "      <td>INDICATION:   ___ with c/o SOB  // ? PNA or CH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  icd_code  \\\n",
       "0    10000117  22927623         0   \n",
       "1    10000117  27988844         0   \n",
       "2    10000980  20897796         0   \n",
       "3    10000980  25911675         0   \n",
       "4    10000980  29659838         0   \n",
       "\n",
       "                                                text  \n",
       "0  EXAMINATION:   CHEST (PA AND LAT)\\n\\nINDICATIO...  \n",
       "1  EXAMINATION:  Left hip radiographs, two views,...  \n",
       "2  EXAMINATION:  BILAT LOWER EXT VEINS\\n\\nINDICAT...  \n",
       "3  EXAMINATION:  Chest radiograph.\\n\\nINDICATION:...  \n",
       "4  INDICATION:   ___ with c/o SOB  // ? PNA or CH...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notedir = './sample_data/mimic-iv/note/'\n",
    "hospdir = './sample_data/mimic-iv/hosp/'\n",
    "diags = pd.read_csv(hospdir + 'diagnoses_icd.csv.gz')\n",
    "d_notes = pd.read_csv(notedir + 'discharge.csv.gz')\n",
    "r_notes = pd.read_csv(notedir + 'radiology.csv.gz')\n",
    "r_notes = r_notes.dropna(subset=['hadm_id'])\n",
    "# Group radiology text into per visit \n",
    "radiology_grouped = r_notes.groupby(['subject_id','hadm_id'])['text'].apply(' '.join).reset_index()\n",
    "\n",
    "diags10 = diags[diags.icd_version == 10]\n",
    "# pancreas = diags10[diags10['icd_code'].astype(str).str.contains('C25')]\n",
    "#encode all diagnoses into either times where pancreatic cancer identified or not\n",
    "diags10.loc[:, 'contains_C25'] = (diags10.loc[:,'icd_code'].str.contains('C25')).astype(int)\n",
    "diags_encoded = diags10.groupby(['subject_id', 'hadm_id']).agg({'contains_C25': 'max'}).reset_index()\n",
    "diags_encoded.rename(columns={'contains_C25': 'icd_code'}, inplace=True)\n",
    "diags_encoded['icd_code'] = diags_encoded['icd_code'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "#just the first 512 of each if true\n",
    "small_df = False\n",
    "\n",
    "if small_df:\n",
    "    merged_df = pd.merge(radiology_grouped.head(512), d_notes.head(512), on=['subject_id', 'hadm_id'], how='right')\n",
    "    merged_df['text'] = merged_df['text_x'] + ' ' + merged_df['text_y']\n",
    "    merged_df = merged_df.drop(columns=['text_x', 'text_y']).dropna(subset=['text'])\n",
    "    merged_df = pd.merge(diags_encoded.head(512), merged_df, on=['subject_id', 'hadm_id'], how='inner').drop(columns=['note_id','note_seq','charttime','storetime', 'note_type'])\n",
    "else:\n",
    "    merged_df = pd.merge(radiology_grouped, d_notes, on=['subject_id', 'hadm_id'], how='right')\n",
    "    merged_df['text'] = merged_df['text_x'] + ' ' + merged_df['text_y']\n",
    "    merged_df = merged_df.drop(columns=['text_x', 'text_y']).dropna(subset=['text'])\n",
    "    merged_df = pd.merge(diags_encoded, merged_df, on=['subject_id', 'hadm_id'], how='inner').drop(columns=['note_id','note_seq','charttime','storetime', 'note_type'])\n",
    "\n",
    "print(merged_df.shape)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 0 Tokenizer\n",
    "\n",
    "Because the clinical notes can be very long (sometimes up to 20,000 words) the tokenizer can take hours to run. We have selected a smaller subset of the data that will be pre processed for model 0. The number of rows with a record containing pancreatic cancer is around 1500, and the number containing other diseases is around 4500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>10006029</td>\n",
       "      <td>20850584</td>\n",
       "      <td>1</td>\n",
       "      <td>EXAMINATION:  Chest radiograph, portable AP up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10006029</td>\n",
       "      <td>25426298</td>\n",
       "      <td>1</td>\n",
       "      <td>INDICATION:  ___ year old man with metastatic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10006431</td>\n",
       "      <td>25589898</td>\n",
       "      <td>1</td>\n",
       "      <td>EXAMINATION:  CTA ABD AND PELVIS\\n\\nINDICATION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>10006431</td>\n",
       "      <td>27715811</td>\n",
       "      <td>1</td>\n",
       "      <td>EXAMINATION:  CHEST (PA AND LAT)\\n\\nINDICATION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10006431</td>\n",
       "      <td>28771670</td>\n",
       "      <td>1</td>\n",
       "      <td>INDICATION:  ___ with upper abdominal pain, hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id   hadm_id  icd_code  \\\n",
       "69    10006029  20850584         1   \n",
       "70    10006029  25426298         1   \n",
       "74    10006431  25589898         1   \n",
       "75    10006431  27715811         1   \n",
       "76    10006431  28771670         1   \n",
       "\n",
       "                                                 text  \n",
       "69  EXAMINATION:  Chest radiograph, portable AP up...  \n",
       "70  INDICATION:  ___ year old man with metastatic ...  \n",
       "74  EXAMINATION:  CTA ABD AND PELVIS\\n\\nINDICATION...  \n",
       "75  EXAMINATION:  CHEST (PA AND LAT)\\n\\nINDICATION...  \n",
       "76  INDICATION:  ___ with upper abdominal pain, hi...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase ratio to get more non-pancreatic cancer data\n",
    "ratio = .05\n",
    "\n",
    "ones = merged_df.index[(merged_df.icd_code == 1)].tolist()\n",
    "zeros = merged_df.index[(merged_df.icd_code == 0)].tolist()\n",
    "\n",
    "N = int(ratio * len(zeros))\n",
    "subset_zeros = random.sample(zeros, N)\n",
    "indices = ones + subset_zeros\n",
    "subset_df = merged_df.iloc[indices]\n",
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process to tokenise first begins by removing some common fluff that exists in the text records. Then run the text through scispacy- a biomedical text processing library which will remove any extranenous filler words and return a more simplifed sequence. Then, using the predefined tokenizer from [Bio_ClinicalBERT](https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT) the text in each row is tokenized and either padded or in a few cases truncated to a max length of 8192. (This whole process takes about 2 seconds per row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "nlp = spacy.load(\"en_core_sci_sm\")\n",
    "def process_row(row):\n",
    "    text = row['text']\n",
    "    text = text.replace('\\n', '')\n",
    "    text = text.replace('___','')\n",
    "    text = text.replace('Name:                   Unit No:    Admission Date:                Discharge Date:    Date of Birth:', '')\n",
    "    doc = nlp(text)\n",
    "    ents = doc.ents\n",
    "    t = ''\n",
    "    for s in ents:\n",
    "        t += s.text\n",
    "        t += ' '\n",
    "    \n",
    "    t = t.replace('=','')\n",
    "    tok = tokenizer(t, return_tensors=\"pt\", max_length=8192, truncation=True, padding='max_length')\n",
    "    return tok\n",
    "\n",
    "tts = subset_df.apply(process_row, axis=1)\n",
    "\n",
    "inps = torch.stack([tok['input_ids'] for tok in tts])\n",
    "inps = inps.squeeze(1).tolist()\n",
    "masks = torch.stack([tok['attention_mask'] for tok in tts])\n",
    "masks = masks.squeeze(1).tolist()\n",
    "subset_df['encoded_text'] = inps\n",
    "subset_df['masks'] = masks\n",
    "subset_df.drop(columns='text').to_pickle('./subset_df.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the tokenised pickle data can be [downloaded here](https://drive.google.com/file/d/1OIG8JaMfg7x5Cl9Losf8a_SJ7smxDic0/view?usp=drive_link) and loaded like this in lieu of running more pre processing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6039, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>encoded_text</th>\n",
       "      <th>masks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>10006029</td>\n",
       "      <td>20850584</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 8179, 2229, 2070, 15241, 170, 1643, 1275...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10006029</td>\n",
       "      <td>25426298</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 12754, 1299, 27154, 27372, 22572, 5326, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10006431</td>\n",
       "      <td>25589898</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 8179, 172, 1777, 170, 1830, 1181, 185, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>10006431</td>\n",
       "      <td>27715811</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 8179, 185, 1161, 5837, 7563, 13335, 2566...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10006431</td>\n",
       "      <td>28771670</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 12754, 3105, 24716, 2489, 1607, 13316, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id   hadm_id  icd_code  \\\n",
       "69    10006029  20850584         1   \n",
       "70    10006029  25426298         1   \n",
       "74    10006431  25589898         1   \n",
       "75    10006431  27715811         1   \n",
       "76    10006431  28771670         1   \n",
       "\n",
       "                                         encoded_text  \\\n",
       "69  [101, 8179, 2229, 2070, 15241, 170, 1643, 1275...   \n",
       "70  [101, 12754, 1299, 27154, 27372, 22572, 5326, ...   \n",
       "74  [101, 8179, 172, 1777, 170, 1830, 1181, 185, 1...   \n",
       "75  [101, 8179, 185, 1161, 5837, 7563, 13335, 2566...   \n",
       "76  [101, 12754, 3105, 24716, 2489, 1607, 13316, 1...   \n",
       "\n",
       "                                                masks  \n",
       "69  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "70  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "74  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "75  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "76  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('subset_df.pkl')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for model 0 \n",
    "\n",
    "The base model used for the pretrained model comes from the [Bio_ClinicalBERT](https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT). This model was trained on ~880 million words from discharge summary notes from the [mimic III dataset](https://mimic.mit.edu/). Their base model can be loaded as follows: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('emilyalsentzer/Bio_ClinicalBERT', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0 training/fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the [original paper](https://www.nature.com/articles/s41467-023-43715-z), the training and testing data was split into the ratio of 95-5 due to memory issues the batch size was reduced to 16 rather than using the original of 48.\n",
    "\n",
    "the model can only handle a max_length of 512, therefore chunking was implemented for better training capture. The model was trained over 5 epochs on a google collab T4 GPU with 15 GB of memory with each epoch taking roughly 12 minutes for a total training time of around an hour.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_ids = df['encoded_text'].tolist()\n",
    "attention_masks = df['masks'].tolist()\n",
    "labels = df['icd_code'].tolist()\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "ids = torch.tensor(input_ids).to(device)\n",
    "masks = torch.tensor(attention_masks).to(device)\n",
    "labels = torch.tensor(labels).to(device)\n",
    "\n",
    "dataset = TensorDataset(ids, masks, labels)\n",
    "\n",
    "train_size = int(0.95 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "max_length = 512\n",
    "chunk_size = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        input_ids_batch, attention_masks_batch, labels_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # chunk\n",
    "        chunk_logits = []\n",
    "        for i in range(0, len(input_ids_batch), chunk_size):\n",
    "            input_ids_chunk = input_ids_batch[:,i:i+chunk_size].to(device)\n",
    "            attention_masks_chunk = attention_masks_batch[:,i:i+chunk_size].to(device)\n",
    "            logits = model(input_ids=input_ids_chunk, attention_mask=attention_masks_chunk).logits\n",
    "            chunk_logits.append(logits)\n",
    "\n",
    "        logits = torch.mean(torch.stack(chunk_logits), dim=0)\n",
    "\n",
    "        loss = criterion(logits, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model was saved and [upload here](https://drive.google.com/file/d/1jehT4uyz6465kX5Ho-ddn1qikzyso5vV/view?usp=drive_link) This tuned model can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('emilyalsentzer/Bio_ClinicalBERT', num_labels=2)\n",
    "path = './5_tuned_model.pth'\n",
    "model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 0 evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was then tested on the remaining 5% of the dataset using the same chunking method as was used in training and yielded the following scores:\n",
    "\n",
    "Accuracy: 0.9511589403973509\n",
    "\n",
    "Precision: 0.907258064516129\n",
    "\n",
    "Recall: 0.8620689655172413\n",
    "\n",
    "F1-score: 0.8840864440078585\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation loop\n",
    "model = BertForSequenceClassification.from_pretrained('emilyalsentzer/Bio_ClinicalBERT', num_labels=2)\n",
    "path = './5_tuned_model.pth'\n",
    "model.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "max_length = 512\n",
    "chunk_size = 512\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids_batch, attention_masks_batch, labels_batch = batch\n",
    "                # chunk\n",
    "        chunk_logits = []\n",
    "        for i in range(0, len(input_ids_batch), chunk_size):\n",
    "            input_ids_chunk = input_ids_batch[:,i:i+chunk_size]\n",
    "            attention_masks_chunk = attention_masks_batch[:,i:i+chunk_size]\n",
    "            logits = model(input_ids=input_ids_chunk, attention_mask=attention_masks_chunk).logits\n",
    "            chunk_logits.append(logits)\n",
    "        logits = torch.mean(torch.stack(chunk_logits), dim=0)\n",
    "        _, predicted = torch.max(logits, dim=1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "        true_labels.extend(labels_batch.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9511589403973509\n",
      "Precision: 0.907258064516129\n",
      "Recall: 0.8620689655172413\n",
      "F1-score: 0.8840864440078585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions)\n",
    "recall = recall_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
